"""add uniqueness constraint to location

Revision ID: fa9f4b687d19
Revises: ee82dd99bfc0
Create Date: 2023-07-13 10:14:27.792938

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = 'fa9f4b687d19'
down_revision = 'ee82dd99bfc0'
branch_labels = None
depends_on = None


def upgrade(engine_name: str) -> None:
    globals()["upgrade_%s" % engine_name]()


def downgrade(engine_name: str) -> None:
    globals()["downgrade_%s" % engine_name]()



def upgrade_catalog() -> None:
    # NOTE: might need to delete duplicate locations first?
    # We use a batch alter table command to cover the use of SQLite dbs
    with op.batch_alter_table("location") as bop:
        bop.create_unique_constraint("uq_location_storage_type", 
                                     ['storage_type', 'file_id'])


def downgrade_catalog() -> None:
    # We use a batch alter table command to cover the use of SQLite dbs. Here we 
    # force SQLite to enforce a naming convention so we can drop the uniqueness 
    # constraint
    naming_conv = {
        "uq": "uq_%(table_name)s_%(column_0_name)s",
    }
    with op.batch_alter_table("location", naming_convention=naming_conv) as bop:
        bop.drop_constraint("uq_location_storage_type", type_='unique')


def upgrade_monitor() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    pass
    # ### end Alembic commands ###


def downgrade_monitor() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    pass
    # ### end Alembic commands ###

